{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nmt_dates_tatoeba.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [
        {
          "file_id": "1Xtn4UTJOeQ999g78urAnPaZgboio8dz5",
          "timestamp": 1524199403566
        }
      ],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python [default]",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "vZJiXbwLZ-WU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h1 align=\"center\">Organization Info</h1> \n",
        "\n",
        "* Дедлайн **DD MM 2018 23:59** для всех групп.\n",
        "* В качестве решения задания нужно прислать ноутбук с подробными комментариями (<span style='color:red'> без присланного решения результат контеста не будет засчитан </span>).\n",
        "* <span style='color:red'>Название команды в контесте должно соответствовать шаблону: НомерГруппы_Имя_Фамилия, например, 594_Ivan_Ivanov</span>."
      ]
    },
    {
      "metadata": {
        "id": "xTnw5Lh6Z-WZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Оформление дз**: \n",
        "- Присылайте выполненное задание на почту ``ml.course.mipt@gmail.com``\n",
        "- Укажите тему письма в следующем формате ``ML2018_fall_<номер_группы>_<фамилия>``, к примеру -- ``ML2018_fall_495_ivanov``\n",
        "- Выполненное дз сохраните в файл ``<фамилия>_<группа>_task<номер>.ipnb, к примеру`` -- ``ivanov_401_task7.ipnb``\n",
        "\n",
        "**Вопросы**:\n",
        "- Присылайте вопросы на почту ``ml.course.mipt@gmail.com``\n",
        "- Укажите тему письма в следующем формате ``ML2018_fall Question <Содержание вопроса>``\n",
        "\n",
        "\n",
        "--------\n",
        "- **PS1:** Используются автоматические фильтры, и просто не найдем ваше дз, если вы неаккуратно его подпишите.\n",
        "- **PS2:**  Просроченный дедлайн снижает максимальный вес задания по формуле, указнной на первом семинаре\n",
        "- **PS3:** Допустимы исправление кода предложенного кода ниже, если вы считаете"
      ]
    },
    {
      "metadata": {
        "id": "4FQqCXxXZ-Wc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h1 align=\"center\">Checking Questions</h1> \n",
        "\n",
        "**Вопрос 1**: Чем LSTM лучше/хуже чем обычная RNN?\n",
        "\n",
        "В LSTM состояние С, которое играет роль памяти,поэтому она эффективнее, чем обычная RNN. Но появляется много весов, значит учить надо дольше и нужно больше данных.\n",
        "\n",
        "**Вопрос 2**:  Выпишите производную $\\frac{d c_{n+1}}{d c_{k}}$ для LSTM http://colah.github.io/posts/2015-08-Understanding-LSTMs/, объясните формулу, когда производная затухает, когда взрывается?\n",
        "\n",
        "$\\frac{d c_{n+1}}{d c_{n}} = f_{n+1} = \\sigma(W_{f}[h_{n+1}, x_{n+1}] + b_{f})$э\n",
        "\n",
        "Так как есть сигмоида, то градиент никогда не превышает 1, следовательно он не взрыватеся.\n",
        "\n",
        "**Вопрос 3**: Зачем нужен TBPTT почему BPTT плох?\n",
        "\n",
        "Так как могут использоваться последовательности произвольной длины то на BPTT нужно протаскивать производные через произвольное количество слоев, что ослождняет \n",
        "вычисления и способствует затуханию. При TBPTT эффекты от этого меньше.\n",
        "\n",
        "\n",
        "**Вопрос 4**: Как комбинировать рекуррентные и сверточные сети, а главное зачем? Приведите несколько примеров реальных задач.\n",
        "\n",
        "Можно один из последних сверточной сети подать на вход рекуррентной сети. Так можно генерировать, к примеру, описания по изображению и распозновать текст на документе.\n",
        "\n",
        "**Вопрос 5**: Можно ли использовать сверточные сети для классификации текстов? Если нет обоснуйте :D, если да то как? как решить проблему с произвольной длинной входа?\n",
        "\n",
        "При использовании фильтров с ядрами вида формы $[n,1]$ получим n-грамм анализ текста. На после convolution слоев поствить RNN, которая на вход принимает выход сверточных слоев и распределение на прошлой итерации. На первом этапе подать туда равномерное распределение.\n",
        "\n",
        "**Вопрос 6**: Attention - что это такое, где применяют и как? Приведите пример использования на какой-нибудь задаче\n",
        "\n",
        "Аttention - механизм, позволяющий использовать hidden-state предыдущих слоев в последущих слоях. На вход подается произведение hidden-state с предыдущего слоя с некоторым набором весов. К примеру, при машинном переводе attention позволяет акцентировать внимание на некоторых частях исходного текста."
      ]
    },
    {
      "metadata": {
        "id": "vpgErJo8Z-Wg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Grading\n",
        "* starting at zero points\n",
        "* +2 for describing your iteration path in a report below (compare models).\n",
        "* +2 for correct check questions\n",
        "* +3 (7 total) for 99% accuracy with simple NMT model on __TEST__ dataset\n",
        "* +3 (10 total) for 99% accuracy with attention NMT model on __TEST__ dataset\n",
        "----\n",
        "* tatoeba bonus for accuracy on __TEST__ dataset:\n",
        "    * +2 for report\n",
        "    * 60% (14 total)\n",
        "    * 65% (16 total)\n",
        "    * 70% (18 total)\n",
        "    * 75% (20 total)\n",
        "    \n",
        "## Bonus points\n",
        "\n",
        "Common ways to get bonus points are:\n",
        "* Get higher score, obviously.\n",
        "* Anything special about your NN. For example \"A super-small/fast NN that gets 99%\" gets a bonus.\n",
        "* Any detailed analysis of the results. (attention maps, whatever)"
      ]
    },
    {
      "metadata": {
        "id": "x1SAlGr0Z-Wj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---"
      ]
    },
    {
      "metadata": {
        "id": "CNEeNE2fZ-Wl",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# additional packages for this notebook"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t1W1gPJbZ-Wy",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "b227f745-bf04-44a3-b624-ff74b75447ea",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525504472098,
          "user_tz": -180,
          "elapsed": 5457,
          "user": {
            "displayName": "Дмитрий Владимирович Родин",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "116592057681709522679"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "! pip install faker tqdm babel"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting faker\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/96/70d8293a839b21133dcb11bb15aec0ed9d2aca9da6a9766a5e21c848615b/Faker-0.8.13-py2.py3-none-any.whl (741kB)\n",
            "\u001b[K    100% |████████████████████████████████| 747kB 6.4MB/s \n",
            "\u001b[?25hCollecting tqdm\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/05/d95bda5a2d833be7593ac0d7eee502acf70d05a4d3a93ef474691a55c531/tqdm-4.23.2-py2.py3-none-any.whl (42kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 12.4MB/s \n",
            "\u001b[?25hCollecting babel\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/94/03/14e68ad12e771a79cf96792f7158d68a7b3d8c7b2badf39e9ef1f65b57d6/Babel-2.5.3-py2.py3-none-any.whl (6.8MB)\n",
            "\u001b[K    100% |████████████████████████████████| 6.8MB 5.6MB/s \n",
            "\u001b[?25hCollecting text-unidecode==1.2 (from faker)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/79/42/d717cc2b4520fb09e45b344b1b0b4e81aa672001dd128c180fabc655c341/text_unidecode-1.2-py2.py3-none-any.whl (77kB)\n",
            "\u001b[K    100% |████████████████████████████████| 81kB 28.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.4 in /usr/local/lib/python3.6/dist-packages (from faker) (2.5.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from faker) (1.11.0)\n",
            "Requirement already satisfied: pytz>=0a in /usr/local/lib/python3.6/dist-packages (from babel) (2018.4)\n",
            "Installing collected packages: text-unidecode, faker, tqdm, babel\n",
            "Successfully installed babel-2.5.3 faker-0.8.13 text-unidecode-1.2 tqdm-4.23.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qZcEtBJ-Z-W-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Task - translation\n",
        "\n",
        "The machine translation is old and well-known field in natural language processing. From the 1950s scientists tried to create a model to automatically translate from say French to English. Nowadays it became possible and the attention mechanism takes great part in that. Here the example image with attention map for the neural machine translation of sample phrase:\n",
        "<p align=\"center\">\n",
        "  <img src=\"http://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/12/Screen-Shot-2015-12-30-at-1.23.48-PM.png\" width=\"400\">\n",
        "</p>"
      ]
    },
    {
      "metadata": {
        "id": "WMqVGHkJZ-XB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In our lab we will concentrate on much simplier task: we will translate from human readable date to machine readable one.\n",
        "\n",
        "1.   List item\n",
        "2.   List item\n",
        "\n",
        "\n",
        "\n",
        "To do this we need to get one more concept - Sequence-to-Sequence language modeling.\n",
        "The idea of such architecture is here:\n",
        "<p aling=\"center\">\n",
        "<img src=\"./img/simple_nmt.jpg\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "There is an Embeding layer at the bottom, the RNN in the middle and softmax as an output."
      ]
    },
    {
      "metadata": {
        "id": "z9tGNB0m5bq3",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Embedding, Bidirectional\n",
        "from keras.layers.core import *\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.models import *\n",
        "from keras.layers.merge import Multiply\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import TimeDistributed\n",
        "\n",
        "import keras.backend as K\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pb8uQ5NIZ-XM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---"
      ]
    },
    {
      "metadata": {
        "id": "d38UMahVZ-XP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Data"
      ]
    },
    {
      "metadata": {
        "id": "DiHiJe835brn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we need to generate data. It will be dates in different text formats and in fixed output format."
      ]
    },
    {
      "metadata": {
        "id": "Lqr3mM4D5bro",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from faker import Faker\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from babel.dates import format_date\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pi8idIsn5brw",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "fake = Faker()\n",
        "\n",
        "FORMATS = ['short',\n",
        "           'medium',\n",
        "           'long',\n",
        "           'full',\n",
        "           'd MMM YYY', \n",
        "           'd MMMM YYY',\n",
        "           'dd MMM YYY',\n",
        "           'd MMM, YYY',\n",
        "           'd MMMM, YYY',\n",
        "           'dd, MMM YYY',\n",
        "           'd MM YY',\n",
        "           'd MMMM YYY',\n",
        "           'MMMM d YYY',\n",
        "           'MMMM d, YYY',\n",
        "           'dd.MM.YY']\n",
        "\n",
        "# change this if you want it to work with another language\n",
        "LOCALES = ['en_US']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "67qzEjMm5br1",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def create_date():\n",
        "    \"\"\"\n",
        "        Creates some fake dates \n",
        "        :returns: tuple containing human readable string, machine readable string, and date object\n",
        "    \"\"\"\n",
        "    dt = fake.date_object()\n",
        "\n",
        "    try:\n",
        "        human_readable = format_date(dt, format=random.choice(FORMATS), locale=random.choice(LOCALES))\n",
        "\n",
        "        case_change = random.choice([0,1,2])\n",
        "        if case_change == 1:\n",
        "            human_readable = human_readable.upper()\n",
        "        elif case_change == 2:\n",
        "            human_readable = human_readable.lower()\n",
        "        # if case_change == 0, do nothing\n",
        "\n",
        "        machine_readable = dt.isoformat()\n",
        "    except AttributeError as e:\n",
        "        return None, None, None\n",
        "\n",
        "    return human_readable, machine_readable, dt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j9eTZ13P5br6",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def create_dataset(n_examples):\n",
        "    \"\"\"\n",
        "        Creates a dataset with n_examples and vocabularies\n",
        "        :n_examples: the number of examples to generate\n",
        "    \"\"\"\n",
        "    human_vocab = set()\n",
        "    machine_vocab = set()\n",
        "    dataset = []\n",
        "\n",
        "    for i in tqdm(range(n_examples)):\n",
        "        h, m, _ = create_date()\n",
        "        if h is not None:\n",
        "            dataset.append((h, m))\n",
        "            human_vocab.update(tuple(h))\n",
        "            machine_vocab.update(tuple(m))\n",
        "\n",
        "    human = dict(zip(list(human_vocab) + ['<unk>', '<pad>'], \n",
        "                     list(range(len(human_vocab) + 2))))\n",
        "    inv_machine = dict(enumerate(list(machine_vocab) + ['<unk>', '<pad>']))\n",
        "    machine = {v:k for k,v in inv_machine.items()}\n",
        " \n",
        "    return dataset, human, machine, inv_machine"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EsQHOc3D5br9",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def string_to_int(string, lenght, vocab):\n",
        "    if len(string) > lenght:\n",
        "        string = string[:lenght]\n",
        "        \n",
        "    rep = list(map(lambda x: vocab.get(x, '<unk>'), string))\n",
        "    \n",
        "    if len(string) < lenght:\n",
        "        rep += [vocab['<pad>']] * (lenght - len(string))\n",
        "    \n",
        "    return rep"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MYU62jZi5bsB",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def int_to_string(ints, inv_vocab):\n",
        "    return [inv_vocab[i] for i in ints]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yTghggDB5bsE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Actually generating data:"
      ]
    },
    {
      "metadata": {
        "id": "As0XeIDa5bsF",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "befda0cc-ee03-4755-d6de-29d9c5c1c31c",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525504514352,
          "user_tz": -180,
          "elapsed": 17955,
          "user": {
            "displayName": "Дмитрий Владимирович Родин",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "116592057681709522679"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "fake.seed(42)\n",
        "random.seed(42)\n",
        "N = int(3e5)\n",
        "dataset, human_vocab, machine_vocab, inv_machine_vocab = create_dataset(N)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 58%|█████▊    | 174723/300000 [00:09<00:07, 17546.87it/s]/usr/local/lib/python3.6/dist-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
            "  TqdmSynchronisationWarning)\n",
            "100%|██████████| 300000/300000 [00:17<00:00, 17405.68it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "qwN8hGFn23Pt",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f4145650-e429-47e9-d32e-144b123444ed",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525504515277,
          "user_tz": -180,
          "elapsed": 644,
          "user": {
            "displayName": "Дмитрий Владимирович Родин",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "116592057681709522679"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#@title Default title text\n",
        "dataset[2]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('tuesday, september 14, 1971', '1971-09-14')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "062jhE7xa2xU",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "TIME_STEPS = 20 # change me if u want"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ITej2gDY5bsN",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "inputs, targets = zip(*dataset)\n",
        "inputs = np.array([string_to_int(i, TIME_STEPS, human_vocab) for i in inputs])\n",
        "targets = [string_to_int(t, TIME_STEPS, machine_vocab) for t in targets]\n",
        "targets = np.array(list(map(lambda x: to_categorical(x, num_classes=len(machine_vocab)), targets)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P_8dFDJPZ-Y-",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "X_train, y_train, X_valid, y_valid, X_test, y_test = (\n",
        "    inputs[:int(2e5)], targets[:int(2e5)], \n",
        "    inputs[int(2e5):-int(5e4)], targets[int(2e5):-int(5e4)],  \n",
        "    inputs[-int(5e4):], targets[-int(5e4):], )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3XTy28oXZ-ZJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---"
      ]
    },
    {
      "metadata": {
        "id": "elSbLKb1Z-ZK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Part 1: Simple NMT"
      ]
    },
    {
      "metadata": {
        "id": "qWo4x0DM5brd",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# :good-enouht:\n",
        "ENCODER_UNITS = 32 # change me if u want\n",
        "DECODER_UNITS = 32 # change me if u want\n",
        "TIME_STEPS = 20 # change me if u want"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QQD_Dy8_0MSx",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# input - [bs; in_time_len]\n",
        "# output - [bs; out_time_len]; out_time_len=10\n",
        "\n",
        "def model_simple_nmt(in_chars, out_chars):\n",
        "    # RNN encoder -> hidden representation -> RNN decoder\n",
        "    inputs = Input(shape=(TIME_STEPS,))\n",
        "\n",
        "    embedding = Embedding(in_chars, in_chars, input_length=TIME_STEPS)(inputs) # перевод данных в вектора\n",
        "    lstm1 = LSTM(ENCODER_UNITS, return_sequences=False)(embedding) # encoder\n",
        "    repeat1 = RepeatVector(TIME_STEPS)(lstm1) # повторяем выход первого слоя, чтобы было что подавать на второй\n",
        "\n",
        "    lstm2 = LSTM(DECODER_UNITS, return_sequences=True, input_shape=(ENCODER_UNITS, TIME_STEPS))(repeat1) # decoder\n",
        "    dense1 = Dense(out_chars)(lstm2) # полносвязный слой и активациооная функция для получения ответа\n",
        "    output = Activation('softmax')(dense1)\n",
        "\n",
        "\n",
        "    model = Model(input=[inputs], output=output)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ztwvgRe35bsJ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "62e27962-12f6-468c-9b04-6cf4214e82ee",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525510056583,
          "user_tz": -180,
          "elapsed": 1156,
          "user": {
            "displayName": "Дмитрий Владимирович Родин",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "116592057681709522679"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "m1 = model_simple_nmt(len(human_vocab), len(machine_vocab))\n",
        "\n",
        "m1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "print(m1.summary())"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "embedding_6 (Embedding)      (None, 20, 60)            3600      \n",
            "_________________________________________________________________\n",
            "lstm_11 (LSTM)               (None, 32)                11904     \n",
            "_________________________________________________________________\n",
            "repeat_vector_3 (RepeatVecto (None, 20, 32)            0         \n",
            "_________________________________________________________________\n",
            "lstm_12 (LSTM)               (None, 20, 32)            8320      \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 20, 13)            429       \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 20, 13)            0         \n",
            "=================================================================\n",
            "Total params: 24,253\n",
            "Trainable params: 24,253\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"ac...)`\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "l_wPSU2t5bsP",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 1091
        },
        "outputId": "e800f3cd-39d9-48df-ba2e-1f40e9bc65a4",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525510757880,
          "user_tz": -180,
          "elapsed": 696623,
          "user": {
            "displayName": "Дмитрий Владимирович Родин",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "116592057681709522679"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "m1.fit(\n",
        "    [X_train], y_train, \n",
        "    validation_data=(X_valid, y_valid),\n",
        "    epochs=30, batch_size=1000, \n",
        "    validation_split=0.1)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 200000 samples, validate on 50000 samples\n",
            "Epoch 1/30\n",
            "200000/200000 [==============================] - 25s 123us/step - loss: 1.3604 - acc: 0.5745 - val_loss: 1.0532 - val_acc: 0.6415\n",
            "Epoch 2/30\n",
            "200000/200000 [==============================] - 23s 114us/step - loss: 1.0120 - acc: 0.6488 - val_loss: 0.9769 - val_acc: 0.6514\n",
            "Epoch 3/30\n",
            " 29000/200000 [===>..........................] - ETA: 18s - loss: 0.9728 - acc: 0.6514"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200000/200000 [==============================] - 23s 114us/step - loss: 0.9502 - acc: 0.6753 - val_loss: 0.9145 - val_acc: 0.7048\n",
            "Epoch 4/30\n",
            "200000/200000 [==============================] - 23s 114us/step - loss: 0.8698 - acc: 0.7167 - val_loss: 0.8255 - val_acc: 0.7248\n",
            "Epoch 5/30\n",
            "108000/200000 [===============>..............] - ETA: 9s - loss: 0.8016 - acc: 0.7393"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200000/200000 [==============================] - 23s 114us/step - loss: 0.7761 - acc: 0.7561 - val_loss: 0.7163 - val_acc: 0.7831\n",
            "Epoch 6/30\n",
            "200000/200000 [==============================] - 23s 114us/step - loss: 0.6452 - acc: 0.7887 - val_loss: 0.5734 - val_acc: 0.7953\n",
            "Epoch 7/30\n",
            "126000/200000 [=================>............] - ETA: 8s - loss: 0.5345 - acc: 0.8044"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200000/200000 [==============================] - 23s 117us/step - loss: 0.5143 - acc: 0.8112 - val_loss: 0.4644 - val_acc: 0.8280\n",
            "Epoch 8/30\n",
            "200000/200000 [==============================] - 23s 115us/step - loss: 0.4320 - acc: 0.8401 - val_loss: 0.4020 - val_acc: 0.8496\n",
            "Epoch 9/30\n",
            "131000/200000 [==================>...........] - ETA: 7s - loss: 0.3841 - acc: 0.8552"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200000/200000 [==============================] - 23s 115us/step - loss: 0.3768 - acc: 0.8577 - val_loss: 0.3559 - val_acc: 0.8643\n",
            "Epoch 10/30\n",
            "200000/200000 [==============================] - 23s 115us/step - loss: 0.3386 - acc: 0.8717 - val_loss: 0.3238 - val_acc: 0.8751\n",
            "Epoch 11/30\n",
            "131000/200000 [==================>...........] - ETA: 7s - loss: 0.3122 - acc: 0.8814"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200000/200000 [==============================] - 23s 114us/step - loss: 0.3069 - acc: 0.8835 - val_loss: 0.2917 - val_acc: 0.8893\n",
            "Epoch 12/30\n",
            "200000/200000 [==============================] - 23s 114us/step - loss: 0.2789 - acc: 0.8955 - val_loss: 0.2646 - val_acc: 0.9022\n",
            "Epoch 13/30\n",
            "131000/200000 [==================>...........] - ETA: 7s - loss: 0.2571 - acc: 0.9059"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200000/200000 [==============================] - 23s 114us/step - loss: 0.2525 - acc: 0.9080 - val_loss: 0.2409 - val_acc: 0.9122\n",
            "Epoch 14/30\n",
            "200000/200000 [==============================] - 23s 115us/step - loss: 0.2275 - acc: 0.9192 - val_loss: 0.2143 - val_acc: 0.9255\n",
            "Epoch 15/30\n",
            "131000/200000 [==================>...........] - ETA: 7s - loss: 0.2063 - acc: 0.9295"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200000/200000 [==============================] - 23s 115us/step - loss: 0.2023 - acc: 0.9313 - val_loss: 0.1903 - val_acc: 0.9366\n",
            "Epoch 16/30\n",
            "200000/200000 [==============================] - 23s 114us/step - loss: 0.1816 - acc: 0.9396 - val_loss: 0.1717 - val_acc: 0.9436\n",
            "Epoch 17/30\n",
            "131000/200000 [==================>...........] - ETA: 7s - loss: 0.1660 - acc: 0.9463"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200000/200000 [==============================] - 23s 115us/step - loss: 0.1629 - acc: 0.9477 - val_loss: 0.1534 - val_acc: 0.9517\n",
            "Epoch 18/30\n",
            "200000/200000 [==============================] - 23s 116us/step - loss: 0.1460 - acc: 0.9549 - val_loss: 0.1380 - val_acc: 0.9582\n",
            "Epoch 19/30\n",
            "131000/200000 [==================>...........] - ETA: 7s - loss: 0.1322 - acc: 0.9608"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200000/200000 [==============================] - 23s 115us/step - loss: 0.1300 - acc: 0.9616 - val_loss: 0.1231 - val_acc: 0.9639\n",
            "Epoch 20/30\n",
            "200000/200000 [==============================] - 24s 119us/step - loss: 0.1158 - acc: 0.9670 - val_loss: 0.1087 - val_acc: 0.9696\n",
            "Epoch 21/30\n",
            "130000/200000 [==================>...........] - ETA: 7s - loss: 0.1054 - acc: 0.9708"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200000/200000 [==============================] - 24s 118us/step - loss: 0.1031 - acc: 0.9716 - val_loss: 0.0968 - val_acc: 0.9735\n",
            "Epoch 22/30\n",
            "200000/200000 [==============================] - 24s 118us/step - loss: 0.0916 - acc: 0.9751 - val_loss: 0.0859 - val_acc: 0.9768\n",
            "Epoch 23/30\n",
            "130000/200000 [==================>...........] - ETA: 7s - loss: 0.0827 - acc: 0.9779"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200000/200000 [==============================] - 24s 118us/step - loss: 0.0811 - acc: 0.9783 - val_loss: 0.0765 - val_acc: 0.9795\n",
            "Epoch 24/30\n",
            "200000/200000 [==============================] - 24s 118us/step - loss: 0.0710 - acc: 0.9819 - val_loss: 0.0663 - val_acc: 0.9843\n",
            "Epoch 25/30\n",
            "130000/200000 [==================>...........] - ETA: 7s - loss: 0.0637 - acc: 0.9852"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200000/200000 [==============================] - 24s 118us/step - loss: 0.0619 - acc: 0.9859 - val_loss: 0.0568 - val_acc: 0.9878\n",
            "Epoch 26/30\n",
            "200000/200000 [==============================] - 23s 117us/step - loss: 0.0536 - acc: 0.9883 - val_loss: 0.0498 - val_acc: 0.9891\n",
            "Epoch 27/30\n",
            "130000/200000 [==================>...........] - ETA: 7s - loss: 0.0483 - acc: 0.9895"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200000/200000 [==============================] - 23s 115us/step - loss: 0.0474 - acc: 0.9896 - val_loss: 0.0464 - val_acc: 0.9894\n",
            "Epoch 28/30\n",
            "200000/200000 [==============================] - 23s 114us/step - loss: 0.0428 - acc: 0.9904 - val_loss: 0.0400 - val_acc: 0.9909\n",
            "Epoch 29/30\n",
            "130000/200000 [==================>...........] - ETA: 7s - loss: 0.0396 - acc: 0.9908"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200000/200000 [==============================] - 23s 114us/step - loss: 0.0388 - acc: 0.9910 - val_loss: 0.0368 - val_acc: 0.9913\n",
            "Epoch 30/30\n",
            "200000/200000 [==============================] - 23s 114us/step - loss: 0.0355 - acc: 0.9915 - val_loss: 0.0340 - val_acc: 0.9917\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f35104c9438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "metadata": {
        "id": "f96inW-QZ-Zy",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "542d43a3-4236-4a39-95ba-8a925c12775d",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525510882429,
          "user_tz": -180,
          "elapsed": 43634,
          "user": {
            "displayName": "Дмитрий Владимирович Родин",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "116592057681709522679"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "m1.evaluate([X_test], y_test)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 43s 864us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.034002687017917636, 0.9916500009727478]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "metadata": {
        "id": "fwYByTjJ5bsS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Lets check our model:"
      ]
    },
    {
      "metadata": {
        "id": "EIMBnjqY5bsS",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "EXAMPLES = ['3 May 1979', '5 Apr 09', '20th February 2016', 'Wed 10 Jul 2007']\n",
        "\n",
        "def run_example(model, input_vocabulary, inv_output_vocabulary, text):\n",
        "    encoded = string_to_int(text, TIME_STEPS, input_vocabulary)\n",
        "    prediction = model.predict(np.array([encoded]))\n",
        "    prediction = np.argmax(prediction[0], axis=-1)\n",
        "    return int_to_string(prediction, inv_output_vocabulary)\n",
        "\n",
        "def run_examples(model, input_vocabulary, inv_output_vocabulary, examples=EXAMPLES):\n",
        "    predicted = []\n",
        "    for example in examples:\n",
        "        predicted.append(''.join(run_example(model, input_vocabulary, inv_output_vocabulary, example)))\n",
        "        print('input:', example)\n",
        "        print('output:', predicted[-1])\n",
        "    return predicted"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0cSByOaY5bsW",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "ad3669b5-d726-47f1-e04f-633344f66af3",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525510948957,
          "user_tz": -180,
          "elapsed": 920,
          "user": {
            "displayName": "Дмитрий Владимирович Родин",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "116592057681709522679"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "run_examples(m1, human_vocab, inv_machine_vocab)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input: 3 May 1979\n",
            "output: 1979-05-03<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "input: 5 Apr 09\n",
            "output: 2009-06-05<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "input: 20th February 2016\n",
            "output: 2016-06-20<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "input: Wed 10 Jul 2007\n",
            "output: 2007-07-06<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1979-05-03<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>',\n",
              " '2009-06-05<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>',\n",
              " '2016-06-20<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>',\n",
              " '2007-07-06<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "metadata": {
        "id": "9dxpHKlg5bsy",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "---"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7pjwvOR2Z-aW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Part 2: All u need is attention"
      ]
    },
    {
      "metadata": {
        "id": "-zDW4e6j5brg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here we use more complex idea that simple seq2seq: we're adding two explicit parts of our network - encoder and decoder (which is applied attention on). The explanatory picture for this idea is below:\n",
        "<p aling=\"center\"><img src=\"https://i.stack.imgur.com/Zwsmz.png\"></p>\n",
        "\n",
        "The lower part of the network is encoding the input to some hidden intermediate representation and the upper part is decoing the hidвen represenataion into some readable output."
      ]
    },
    {
      "metadata": {
        "id": "yhVDN9n1Z-ac",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# :good-enouht:\n",
        "ENCODER_UNITS = 32 # change me if u want\n",
        "DECODER_UNITS = 32 # change me if u want\n",
        "TIME_STEPS = 20 # change me if u want"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZlEvwKHKzyYP",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import merge\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a60mm6evv4GA",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def model_not_so_simple_nmt(in_chars, out_chars):\n",
        "    # RNN encoder -> hidden representation -> RNN decoder\n",
        "    inputs = Input(shape=(TIME_STEPS,))\n",
        "    embedding = Embedding(in_chars, in_chars, input_length=TIME_STEPS)(inputs) # перевод данных в вектора\n",
        "    lstm1 = LSTM(ENCODER_UNITS, return_sequences=True)(embedding)  # encoder\n",
        "    \n",
        "    #генерируем матрицу весов и мерджим её со входом предыдущего слоя\n",
        "    input_dim = int(lstm1.shape[2])\n",
        "    a = Permute((2, 1))(lstm1)\n",
        "    a = Reshape((input_dim, TIME_STEPS))(a) \n",
        "    a = Dense(TIME_STEPS, activation='softmax')(a)\n",
        "    a_probs = Permute((2, 1), name='attention_vec')(a)\n",
        "    result = merge([lstm1, a_probs], name='attention_mul', mode='mul')\n",
        "\n",
        "    lstm2 = LSTM(DECODER_UNITS, return_sequences=True, input_shape=(ENCODER_UNITS, TIME_STEPS))(result)# decoder\n",
        "    dense1 = Dense(out_chars)(lstm2)# полносвязный слой и активациооная функция для получения ответа\n",
        "    output = Activation('softmax')(dense1)\n",
        "\n",
        "\n",
        "    model = Model(input=[inputs], output=output)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZKW1Jx0RxDWz",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "outputId": "3b52bdd1-d7a1-44f9-c0f0-77b03d8156d5",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525505675721,
          "user_tz": -180,
          "elapsed": 1204,
          "user": {
            "displayName": "Дмитрий Владимирович Родин",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "116592057681709522679"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "m = model_not_so_simple_nmt(len(human_vocab), len(machine_vocab))\n",
        "\n",
        "m.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "print(m.summary())"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/keras/legacy/layers.py:465: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
            "  name=name)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_4 (Embedding)         (None, 20, 60)       3600        input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_7 (LSTM)                   (None, 20, 32)       11904       embedding_4[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "permute_3 (Permute)             (None, 32, 20)       0           lstm_7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "reshape_3 (Reshape)             (None, 32, 20)       0           permute_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 32, 20)       420         reshape_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "attention_vec (Permute)         (None, 20, 32)       0           dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "attention_mul (Merge)           (None, 20, 32)       0           lstm_7[0][0]                     \n",
            "                                                                 attention_vec[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "lstm_8 (LSTM)                   (None, 20, 32)       8320        attention_mul[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 20, 13)       429         lstm_8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 20, 13)       0           dense_6[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 24,673\n",
            "Trainable params: 24,673\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"ac...)`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "mK9dEA_05phs",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# 133 эпох с batch size 1000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3sgbws5exMAc",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "e658246e-3d99-44f7-edee-506a8c55c1b6",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525509966304,
          "user_tz": -180,
          "elapsed": 24227,
          "user": {
            "displayName": "Дмитрий Владимирович Родин",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "116592057681709522679"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "m.fit(\n",
        "    [X_train], y_train, \n",
        "    validation_data=(X_valid, y_valid),\n",
        "    epochs=1, batch_size=1000, \n",
        "    validation_split=0.1)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 200000 samples, validate on 50000 samples\n",
            "Epoch 1/1\n",
            "200000/200000 [==============================] - 24s 118us/step - loss: 0.0231 - acc: 0.9913 - val_loss: 0.0229 - val_acc: 0.9913\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3510536470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "metadata": {
        "id": "Di2dpALGZ-bC",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3954fa4d-3ff6-4e0d-dfcb-c42196275d44",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525510015926,
          "user_tz": -180,
          "elapsed": 45552,
          "user": {
            "displayName": "Дмитрий Владимирович Родин",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "116592057681709522679"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "m.evaluate([X_test], y_test)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 44s 874us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.022750731980353593, 0.9913490004730224]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "metadata": {
        "id": "QWr6A_CTZ-bL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Report\n",
        "\n",
        "* final architectures\n",
        "\n",
        "1) Простая сеть \n",
        "- embedding  - перевод входа в вектор\n",
        "- LSTM - кодирование входа\n",
        "- repeatLayer - размножение последнего выхода для передачи в декодер\n",
        "- LSTM - декодирование\n",
        "- dence + activation - получение результата\n",
        "\n",
        "2) Сеть с вниманием\n",
        "\n",
        "- embedding  - перевод входа в вектор\n",
        "- LSTM - кодирование входа\n",
        "\n",
        "- attention generation block :\n",
        "- - permute - меняем размерность входа\n",
        "- - reshape - нужен, чтобы убедиться, что размерность поменялась правильно\n",
        "- - dence  + softmax - генерируем некоторые числа и переводим их в веса от 0 до 1\n",
        "- - multiply - применяем веса ко входу\n",
        "\n",
        "- LSTM - декодирование\n",
        "- dence + activation - получение результата\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "* comparison\n",
        "\n",
        "Вторая сеть учится дольше до нужного результата так как в ней просто больше весов.\n",
        "* as well as training method and tricks\n"
      ]
    },
    {
      "metadata": {
        "id": "CYDcYsndZ-bR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---"
      ]
    },
    {
      "metadata": {
        "id": "lFvz-_8gZ-bV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Part 3*: tatoeba - real NMT"
      ]
    },
    {
      "metadata": {
        "id": "7tKTXzVVZ-bX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Data"
      ]
    },
    {
      "metadata": {
        "id": "9cLHSav9Z-bZ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# dataset from http://www.manythings.org/anki/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4Fhiz_A7Z-bn",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "7ce9ff0d-c4b3-4c9e-caf5-137f24b628dc",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525510973645,
          "user_tz": -180,
          "elapsed": 2878,
          "user": {
            "displayName": "Дмитрий Владимирович Родин",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "116592057681709522679"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "! wget http://www.manythings.org/anki/rus-eng.zip"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-05-05 09:02:53--  http://www.manythings.org/anki/rus-eng.zip\r\n",
            "Resolving www.manythings.org (www.manythings.org)... 104.24.109.196, 104.24.108.196, 2400:cb00:2048:1::6818:6dc4, ...\r\n",
            "Connecting to www.manythings.org (www.manythings.org)|104.24.109.196|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6366669 (6.1M) [application/zip]\n",
            "Saving to: ‘rus-eng.zip’\n",
            "\n",
            "rus-eng.zip         100%[===================>]   6.07M  14.0MB/s    in 0.4s    \n",
            "\n",
            "2018-05-05 09:02:53 (14.0 MB/s) - ‘rus-eng.zip’ saved [6366669/6366669]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "r0S0UPvTZ-b4",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "3a9c7748-4aed-4eec-d1c8-d3dfbd297050",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525510976927,
          "user_tz": -180,
          "elapsed": 2037,
          "user": {
            "displayName": "Дмитрий Владимирович Родин",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "116592057681709522679"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "! unzip ./rus-eng.zip"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  ./rus-eng.zip\n",
            "  inflating: rus.txt                 \n",
            "  inflating: _about.txt              \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OLn55n-EZ-cB",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "with open(\"./rus.txt\") as fin:\n",
        "    data = fin.readlines()\n",
        "data = list(map(lambda x: x.replace(\"\\n\", \"\").lower(), data))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KfIHDf1-Z-cJ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "72759428-9e5e-4790-ab19-0c7ce25a51aa",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525510982719,
          "user_tz": -180,
          "elapsed": 1166,
          "user": {
            "displayName": "Дмитрий Владимирович Родин",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "116592057681709522679"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300108"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "metadata": {
        "id": "lzTkUDcmZ-cP",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "data = data[:int(1e5)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "soT515J4Z-cY",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5a3fe065-2559-4f0f-e09b-432ef9975c9d",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525510988626,
          "user_tz": -180,
          "elapsed": 1035,
          "user": {
            "displayName": "Дмитрий Владимирович Родин",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "116592057681709522679"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "metadata": {
        "id": "Hid_horwZ-ce",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "72cf47d7-02f9-4a9b-fe6d-aeb3b608192a",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525510990932,
          "user_tz": -180,
          "elapsed": 747,
          "user": {
            "displayName": "Дмитрий Владимирович Родин",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "116592057681709522679"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "data[-1]"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'tom is here to see you.\\tк тебе том пришёл.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "metadata": {
        "id": "meElEFFQZ-cl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "----"
      ]
    },
    {
      "metadata": {
        "id": "w8yQFpYaZ-cn",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "source = list(map(lambda x: x.split(\"\\t\")[0], data))\n",
        "target = list(map(lambda x: x.split(\"\\t\")[1], data))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yv8jVUo_Z-cw",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "source_vocab = set(\"\".join(source).strip())\n",
        "target_vocab = set(\"\".join(target).strip())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yZd0TPorZ-c7",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "source_vocab = dict(zip(\n",
        "    list(source_vocab) + ['<unk>', '<pad>'], \n",
        "    list(range(len(source_vocab) + 2))))\n",
        "target_vocab = dict(zip(\n",
        "    list(target_vocab) + ['<unk>', '<pad>'], \n",
        "    list(range(len(target_vocab) + 2))))\n",
        "inv_target_vocab = dict(enumerate(list(target_vocab) + ['<unk>', '<pad>']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "It_W1l3rZ-dF",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "TIME_STEPS = 32\n",
        "ENCODER_UNITS = 256\n",
        "DECODER_UNITS = 256"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oFUBbin9Z-da",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def model_simple_nmt_tatoeba(in_chars, out_chars):\n",
        "    inputs = Input(shape=(TIME_STEPS,))\n",
        "    embedding = Embedding(in_chars, in_chars, input_length=TIME_STEPS)(inputs) # перевод данных в вектора\n",
        "    lstm1 = LSTM(ENCODER_UNITS, return_sequences=True)(embedding)  # encoder\n",
        "    \n",
        "    #генерируем матрицу весов и мерджим её со входом предыдущего слоя\n",
        "    input_dim = int(lstm1.shape[2])\n",
        "    a = Permute((2, 1))(lstm1)\n",
        "    a = Reshape((input_dim, TIME_STEPS))(a) \n",
        "    a = Dense(TIME_STEPS, activation='softmax')(a)\n",
        "    a_probs = Permute((2, 1), name='attention_vec')(a)\n",
        "    result = merge([lstm1, a_probs], name='attention_mul', mode='mul')\n",
        "\n",
        "    lstm2 = LSTM(DECODER_UNITS, return_sequences=True, input_shape=(ENCODER_UNITS, TIME_STEPS))(result)# decoder\n",
        "    dense1 = Dense(out_chars)(lstm2)# полносвязный слой и активациооная функция для получения ответа\n",
        "    output = Activation('softmax')(dense1)\n",
        "\n",
        "\n",
        "    model = Model(input=[inputs], output=output)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nb357Zh2Z-dp",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "outputId": "cea3bdf6-574f-4631-e002-1cb1fde66473",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525511263968,
          "user_tz": -180,
          "elapsed": 1311,
          "user": {
            "displayName": "Дмитрий Владимирович Родин",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "116592057681709522679"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "m_t = model_simple_nmt_tatoeba(len(source_vocab), len(target_vocab))\n",
        "\n",
        "m_t.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "print(m_t.summary())"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/keras/legacy/layers.py:465: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
            "  name=name)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_11 (InputLayer)           (None, 32)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_11 (Embedding)        (None, 32, 54)       2916        input_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_21 (LSTM)                  (None, 32, 256)      318464      embedding_11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "permute_6 (Permute)             (None, 256, 32)      0           lstm_21[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "reshape_6 (Reshape)             (None, 256, 32)      0           permute_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_15 (Dense)                (None, 256, 32)      1056        reshape_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "attention_vec (Permute)         (None, 32, 256)      0           dense_15[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "attention_mul (Merge)           (None, 32, 256)      0           lstm_21[0][0]                    \n",
            "                                                                 attention_vec[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "lstm_22 (LSTM)                  (None, 32, 256)      525312      attention_mul[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_16 (Dense)                (None, 32, 87)       22359       lstm_22[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 32, 87)       0           dense_16[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 870,107\n",
            "Trainable params: 870,107\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"ac...)`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "03T9DrMYZ-d9",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "inputs = np.array([string_to_int(i, TIME_STEPS, source_vocab) for i in source])\n",
        "targets = [string_to_int(t, TIME_STEPS, target_vocab) for t in target]\n",
        "targets = np.array(list(map(lambda x: to_categorical(x, num_classes=len(target_vocab)), targets)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U0KcYO2uZ-eR",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 1431
        },
        "outputId": "b7133056-a593-47e7-8b1d-cd3647ea323b",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525513186217,
          "user_tz": -180,
          "elapsed": 1324815,
          "user": {
            "displayName": "Дмитрий Владимирович Родин",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "116592057681709522679"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "m_t.fit(\n",
        "    [inputs], targets, \n",
        "    epochs=40, batch_size=1000, \n",
        "    validation_split=0.1)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 90000 samples, validate on 10000 samples\n",
            "Epoch 1/40\n",
            "90000/90000 [==============================] - 33s 369us/step - loss: 1.9137 - acc: 0.5054 - val_loss: 2.3592 - val_acc: 0.3893\n",
            "Epoch 2/40\n",
            "90000/90000 [==============================] - 33s 367us/step - loss: 1.8940 - acc: 0.5097 - val_loss: 2.3342 - val_acc: 0.3952\n",
            "Epoch 3/40\n",
            "90000/90000 [==============================] - 33s 368us/step - loss: 1.8780 - acc: 0.5133 - val_loss: 2.3211 - val_acc: 0.3988\n",
            "Epoch 4/40\n",
            "39000/90000 [============>.................] - ETA: 18s - loss: 1.8663 - acc: 0.5160"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "90000/90000 [==============================] - 33s 368us/step - loss: 1.8623 - acc: 0.5171 - val_loss: 2.3044 - val_acc: 0.4019\n",
            "Epoch 5/40\n",
            "90000/90000 [==============================] - 33s 368us/step - loss: 1.8482 - acc: 0.5205 - val_loss: 2.2896 - val_acc: 0.4063\n",
            "Epoch 6/40\n",
            "90000/90000 [==============================] - 33s 368us/step - loss: 1.8300 - acc: 0.5245 - val_loss: 2.2770 - val_acc: 0.4086\n",
            "Epoch 7/40\n",
            "84000/90000 [===========================>..] - ETA: 2s - loss: 1.8154 - acc: 0.5279"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "90000/90000 [==============================] - 33s 368us/step - loss: 1.8140 - acc: 0.5283 - val_loss: 2.2589 - val_acc: 0.4140\n",
            "Epoch 8/40\n",
            "90000/90000 [==============================] - 33s 368us/step - loss: 1.7988 - acc: 0.5323 - val_loss: 2.2487 - val_acc: 0.4182\n",
            "Epoch 9/40\n",
            "90000/90000 [==============================] - 33s 368us/step - loss: 1.7851 - acc: 0.5357 - val_loss: 2.2352 - val_acc: 0.4212\n",
            "Epoch 10/40\n",
            "90000/90000 [==============================] - 33s 367us/step - loss: 1.7708 - acc: 0.5389 - val_loss: 2.2404 - val_acc: 0.4227\n",
            "Epoch 11/40\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "90000/90000 [==============================] - 33s 368us/step - loss: 1.7560 - acc: 0.5418 - val_loss: 2.2104 - val_acc: 0.4263\n",
            "Epoch 12/40\n",
            "90000/90000 [==============================] - 33s 368us/step - loss: 1.7435 - acc: 0.5443 - val_loss: 2.2017 - val_acc: 0.4275\n",
            "Epoch 13/40\n",
            "90000/90000 [==============================] - 33s 368us/step - loss: 1.7318 - acc: 0.5468 - val_loss: 2.1939 - val_acc: 0.4303\n",
            "Epoch 14/40\n",
            "76000/90000 [========================>.....] - ETA: 4s - loss: 1.7188 - acc: 0.5495"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "90000/90000 [==============================] - 33s 368us/step - loss: 1.7186 - acc: 0.5496 - val_loss: 2.1841 - val_acc: 0.4318\n",
            "Epoch 15/40\n",
            "90000/90000 [==============================] - 33s 368us/step - loss: 1.7076 - acc: 0.5522 - val_loss: 2.1781 - val_acc: 0.4335\n",
            "Epoch 16/40\n",
            "90000/90000 [==============================] - 33s 368us/step - loss: 1.6957 - acc: 0.5547 - val_loss: 2.1760 - val_acc: 0.4347\n",
            "Epoch 17/40\n",
            "89000/90000 [============================>.] - ETA: 0s - loss: 1.6860 - acc: 0.5569"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r90000/90000 [==============================] - 33s 367us/step - loss: 1.6859 - acc: 0.5569 - val_loss: 2.1700 - val_acc: 0.4365\n",
            "Epoch 18/40\n",
            "90000/90000 [==============================] - 33s 368us/step - loss: 1.6749 - acc: 0.5591 - val_loss: 2.1656 - val_acc: 0.4385\n",
            "Epoch 19/40\n",
            "90000/90000 [==============================] - 33s 368us/step - loss: 1.6646 - acc: 0.5609 - val_loss: 2.1580 - val_acc: 0.4391\n",
            "Epoch 20/40\n",
            "52000/90000 [================>.............] - ETA: 13s - loss: 1.6533 - acc: 0.5631"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "90000/90000 [==============================] - 33s 368us/step - loss: 1.6545 - acc: 0.5628 - val_loss: 2.1589 - val_acc: 0.4409\n",
            "Epoch 21/40\n",
            "90000/90000 [==============================] - 33s 368us/step - loss: 1.6446 - acc: 0.5647 - val_loss: 2.1617 - val_acc: 0.4419\n",
            "Epoch 22/40\n",
            "90000/90000 [==============================] - 33s 368us/step - loss: 1.6370 - acc: 0.5664 - val_loss: 2.1512 - val_acc: 0.4415\n",
            "Epoch 23/40\n",
            "85000/90000 [===========================>..] - ETA: 1s - loss: 1.6262 - acc: 0.5681"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "90000/90000 [==============================] - 33s 368us/step - loss: 1.6269 - acc: 0.5680 - val_loss: 2.1484 - val_acc: 0.4409\n",
            "Epoch 24/40\n",
            "90000/90000 [==============================] - 33s 368us/step - loss: 1.6192 - acc: 0.5695 - val_loss: 2.1470 - val_acc: 0.4438\n",
            "Epoch 25/40\n",
            "90000/90000 [==============================] - 33s 369us/step - loss: 1.6105 - acc: 0.5710 - val_loss: 2.1408 - val_acc: 0.4439\n",
            "Epoch 26/40\n",
            "90000/90000 [==============================] - 33s 367us/step - loss: 1.6168 - acc: 0.5697 - val_loss: 2.2457 - val_acc: 0.4214\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 27/40\n",
            "90000/90000 [==============================] - 33s 367us/step - loss: 1.6727 - acc: 0.5600 - val_loss: 2.1489 - val_acc: 0.4425\n",
            "Epoch 28/40\n",
            "90000/90000 [==============================] - 33s 368us/step - loss: 1.6183 - acc: 0.5701 - val_loss: 2.1543 - val_acc: 0.4441\n",
            "Epoch 29/40\n",
            "90000/90000 [==============================] - 33s 367us/step - loss: 1.5998 - acc: 0.5732 - val_loss: 2.1392 - val_acc: 0.4456\n",
            "Epoch 30/40\n",
            "68000/90000 [=====================>........] - ETA: 7s - loss: 1.5907 - acc: 0.5748"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "90000/90000 [==============================] - 33s 367us/step - loss: 1.5899 - acc: 0.5751 - val_loss: 2.1366 - val_acc: 0.4459\n",
            "Epoch 31/40\n",
            "90000/90000 [==============================] - 33s 367us/step - loss: 1.5814 - acc: 0.5765 - val_loss: 2.1389 - val_acc: 0.4457\n",
            "Epoch 32/40\n",
            "90000/90000 [==============================] - 33s 367us/step - loss: 1.5730 - acc: 0.5781 - val_loss: 2.1379 - val_acc: 0.4472\n",
            "Epoch 33/40\n",
            "87000/90000 [============================>.] - ETA: 1s - loss: 1.5655 - acc: 0.5796"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "90000/90000 [==============================] - 33s 368us/step - loss: 1.5656 - acc: 0.5795 - val_loss: 2.1456 - val_acc: 0.4466\n",
            "Epoch 34/40\n",
            "90000/90000 [==============================] - 33s 368us/step - loss: 1.5591 - acc: 0.5805 - val_loss: 2.1471 - val_acc: 0.4477\n",
            "Epoch 35/40\n",
            "90000/90000 [==============================] - 33s 368us/step - loss: 1.5507 - acc: 0.5821 - val_loss: 2.1497 - val_acc: 0.4449\n",
            "Epoch 36/40\n",
            "90000/90000 [==============================] - 33s 368us/step - loss: 1.5445 - acc: 0.5832 - val_loss: 2.1386 - val_acc: 0.4486\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 37/40\n",
            "90000/90000 [==============================] - 33s 368us/step - loss: 1.5382 - acc: 0.5844 - val_loss: 2.1489 - val_acc: 0.4481\n",
            "Epoch 38/40\n",
            "90000/90000 [==============================] - 33s 368us/step - loss: 1.5315 - acc: 0.5854 - val_loss: 2.1511 - val_acc: 0.4461\n",
            "Epoch 39/40\n",
            "90000/90000 [==============================] - 33s 368us/step - loss: 1.5258 - acc: 0.5868 - val_loss: 2.1579 - val_acc: 0.4490\n",
            "Epoch 40/40\n",
            "68000/90000 [=====================>........] - ETA: 7s - loss: 1.5166 - acc: 0.5880"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "90000/90000 [==============================] - 33s 368us/step - loss: 1.5189 - acc: 0.5877 - val_loss: 2.1518 - val_acc: 0.4451\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f34ddb69278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "metadata": {
        "id": "tVuWdJATpoEN",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "m.evaluate([X_test], y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "du6l-1wrZ-ea",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "run_example(m_t, source_vocab, inv_target_vocab, 'hello')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G-8NCjH_Z-eh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Tatoeba Report\n",
        "\n",
        "* final architectures\n",
        "* comparison\n",
        "* as well as training method and tricks\n"
      ]
    },
    {
      "metadata": {
        "id": "tyr-EkKDZ-ei",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}