{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 14pt\">MIPT, Applied ML, Autumn 2018</span>\n",
    "\n",
    "<span style=\"font-size: 16pt\"> HW #4: Approximate RL homework\n",
    "\n",
    "<span style=\"color:red; font-size: 14pt;\"> Дедлайн 19.11.2018 23:59 </span>\n",
    "\n",
    "<span style=\"color:blue; font-size: 12pt\">Valentin Malykh </span>,\n",
    "<span style=\"color:blue; font-size: 12pt; font-family: 'Verdana'\">val@maly.hk</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Оформление дз**: \n",
    "- Выполненное задание требуется отправлять через <a href='https://goo.gl/forms/XPSIbwp7wPxB4SsI3'>форму </a>\n",
    "\n",
    "- Выполненное дз прикрепляйте в формате файла ``<фамилия>_<группа>_task<номер>.ipynb``, например: ``ivanov_594_task4.ipynb`` \n",
    "\n",
    "**Вопросы**:\n",
    "- Вопросы присылайте в канал в телеграмме ``[Fall 2018]ML Seminars``\n",
    "\n",
    "--------\n",
    "- **PS1**: Будьте внимательны при заполнении формы, когда отправляете ДЗ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Практическое задание (100%)</h1>\n",
    "Описание находится по ссылке: https://gist.github.com/madrugado/1262c3077bf7d8ac8166e4350f0f67e2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При выполнении задания использовался https://github.com/dgriff777/a3c_continuous\n",
    "\n",
    "Модель обучается примерно 15 часов, после чего выдает результат на 300 эпохах примерно $300 \\pm 10$.\n",
    "\n",
    "Результаты промежучного обучения сохраняются в файл best_model. В файле current_best_model уже обученная модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import gym\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import math\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from collections import defaultdict\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<subprocess.Popen at 0x194575eb470>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#эта ячейка запускает обучение модели.\n",
    "import subprocess\n",
    "subprocess.Popen([\"python\", \"main.py\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import A3C_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(num_runs, model_file, render=False):\n",
    "    env = gym.make('BipedalWalker-v2')\n",
    "    action_dim = env.action_space.shape[0]\n",
    "    state_dim = env.observation_space.shape[0]\n",
    "    actor = A3C_Model(state_dim, action_dim)\n",
    "    rewards = []\n",
    "\n",
    "    for i in range(num_runs):\n",
    "        state_dict = torch.load(model_file)\n",
    "        actor.load_state_dict(state_dict)\n",
    "        actor.eval()\n",
    "        total_reward = 0\n",
    "        new_obs = env.reset()\n",
    "        actor.train(False)\n",
    "        cx = Variable(torch.zeros(1, 128))\n",
    "        hx = Variable(torch.zeros(1, 128))\n",
    "        while True:\n",
    "            if render:\n",
    "                env.render()\n",
    "            obs = torch.from_numpy(new_obs).float()\n",
    "            value, mu, sigma, (hx, cx) = actor((Variable(obs), (hx, cx)))\n",
    "            mu = torch.clamp(mu.data, -1.0, 1.0)\n",
    "            action = mu.cpu().numpy()[0]\n",
    "            new_obs, reward, done, info = env.step(action)\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                rewards.append(total_reward)\n",
    "                break\n",
    "    print(np.mean(rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\n",
      "WARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\n",
      "300.0299086789108\n"
     ]
    }
   ],
   "source": [
    "evaluate(300, 'current_best_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(300, 'best_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gym",
   "language": "python",
   "name": "gym"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
