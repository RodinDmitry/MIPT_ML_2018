{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 14pt\">MIPT, Applied ML, Autumn 2018</span>\n",
    "\n",
    "<span style=\"font-size: 16pt\"> HW #3 Ранжирование, тематическое моделирование, обработка естественного языка.\n",
    "\n",
    "<span style=\"color:red; font-size: 14pt;\"> Дедлайн 31.10.2018 23:59 </span>\n",
    "\n",
    "<span style=\"color:blue; font-size: 12pt\">Alexey Romanenko </span>,\n",
    "<span style=\"color:blue; font-size: 12pt; font-family: 'Verdana'\">alexromsput@gmail.com</span>\n",
    "\n",
    "<span style=\"color:blue; font-size: 12pt\">Zukhba Anastasia </span>,\n",
    "<span style=\"color:blue; font-size: 12pt; font-family: 'Verdana'\">a__l@mail.ru</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Оформление дз**: \n",
    "- Выполненное задание требуется отправлять через <a href='https://goo.gl/forms/XPSIbwp7wPxB4SsI3'>форму </a>\n",
    "- Выполненное дз прикрепляйте в формате файла ``<фамилия>_<группа>_task<номер>.ipynb``, например: ``ivanov_594_task1.ipynb`` \n",
    "\n",
    "**Вопросы**:\n",
    "- Вопросы присылайте на почту ml.course.mipt@gmail.com\n",
    "- Укажите тему письма в следующем формате ``ML2018_fall_Question_<Тема вопроса>``\n",
    "\n",
    "--------\n",
    "- **PS1**: Будьте внимательны при заполнении формы, когда отправляете ДЗ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Теоретическая часть (25%) </h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Контрольные вопросы (2%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1)** Что является объектом в задаче обучения ранжированию? Какой смысл имеют целевые метки? Какие объекты сравнимы между собой?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2)** В чём преимущество метрики NDCG перед метрикой MAP?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3)** Опишите причину неустойчивости PLSA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4)** На каких выборках наиболее заметна разница в работе PLSA и LDA?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5)** По каким причинам в ЕМ-алгоритме для тематического моделирования E-шаг встраивается внутрь М-шага?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6)**  Опишите применение тематического моделирования в задаче информационного поиска."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7)** В чем основная причина сложности обработки русского языка по сравнению с английским?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8)**  Каким образом парсинг зависимостей между словами помогает в решении задач обработки естественного языка?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9)**  Что такое кореференции?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10)**  В чем отличие между CBOW и Skip-gram?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача 1** (2%)\n",
    "\n",
    "Посчитайте PageRank для заданного графа вручную и при помощи алгоритма, описанного в семинаре. Результаты сравните.\n",
    "\n",
    " <img width=300 src=\"./gr1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Задача 2** (2%)\n",
    "\n",
    "Пользователь браузера в дополнение к кликам по ссылкам один раз может перейти по кнопке *Назад* и вернуться на предыдущую страницу. Можно ли такую модель описать с помощью однородной марковской цепи? Если да, опишите, если нет, докажите."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Идея** Если можно построить новый граф переходов, то можно построить однородную марковскую цепь.\n",
    "\n",
    "Обозначим страницу состоянием x_i. Введем дополниетльные состояния вида $ (x_i,x_j) $, где первое состояние соответствует странице, с которой пришли. \n",
    "\n",
    "Вершины нового графа - старые $x_i$ и новые $ (x_i,x_j) $\n",
    "\n",
    "Для каждого ребра графа $x_i \\rightarrow x_j $ введем ребра нового графа:\n",
    "\n",
    "$1) x_i \\rightarrow (x_i, x_j) $ - Переход вперед\n",
    "\n",
    "$2) \\forall k (x_k, x_i) \\rightarrow (x_i, x_j) $ - Переход вперед \n",
    "\n",
    "$2) (x_i, x_j) \\rightarrow x_i $ - Переход назад\n",
    "\n",
    "Получим граф переходов с возможностью возвращения назад на одни шаг. Соответственно, по этому графу можно построить стацонарную марковскую цепь."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача 3** (3%)\n",
    "\n",
    "Опишите вероятностные предположения, на которые опирается  TF-IDF при подсчете вероятностей.\n",
    "\n",
    "Пусть задана колекция текстовых документов $d_1, d_2,\\ldots, d_n$, состоящая из двух видов слов: $w_1$ и $w_2$. В документе $d_i$ ровно $k_{i1}$ слов $w_1$ и $k_{i2}$ слов $w_2$.\n",
    "\n",
    "Оцените вероятность втретить $k$ раз слово $w_1$. Сравните с оценкой вероятности, используемой в TF-IDF. \n",
    "\n",
    "Совпадают ли эти значения? Если нет, проведите анализ \"источника\" различий.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача 4** (2%)\n",
    "\n",
    "Задано 10 документов. Их отранжировали идеально, а затем 4 и 6 документы поменяли местами. \n",
    "Подсчитайте коэффициент ранговой корреляции (τ Кенделла)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача 5** (4%)\n",
    "\n",
    "С какой целью общеупотребительные слова исключают из рассмотрения при построении тематической модели? Если их не исключать, как это отразится на матрицах $\\Phi$ и $\\Theta$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача 6** (5%)\n",
    "\n",
    "Здадано значение $KL(P∥Q)$. Можно ли оценить значение $KL(Q∥P)$? Если да, то оцените; если нет, то обоснуйте."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$KL(P∥Q) - KL(Q∥P) = \\int (P(x) + Q(x)) ln\\frac {P(x)}{Q(x)} dx \\neq 0$ в общем случае. Значит дивергенция Кульбака-Лейблера не симметрична.\n",
    "\n",
    "$KL(P||Q) = \\int P(x) ln\\frac{P(x)}{Q(x)} dx \\leq \\int |P(x)| |ln\\frac{P(x)}{Q(x)}| dx  = \\int |ln\\frac{P(x)}{Q(x)}| dx$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача 7** (+5%) \n",
    "\n",
    "Рассмотрим пример из семинара:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a5952e122a0f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mspacy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdisplacy\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m text = \"\"\"But Google is starting from behind. The company made a late push\n\u001b[0;32m      5\u001b[0m \u001b[0minto\u001b[0m \u001b[0mhardware\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mApple\u001b[0m\u001b[0;31m’\u001b[0m\u001b[0ms\u001b[0m \u001b[0mSiri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mavailable\u001b[0m \u001b[0mon\u001b[0m \u001b[0miPhones\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mAmazon\u001b[0m\u001b[0;31m’\u001b[0m\u001b[0ms\u001b[0m \u001b[0mAlexa\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "text = \"\"\"But Google is starting from behind. The company made a late push\n",
    "into hardware, and Apple’s Siri, available on iPhones, and Amazon’s Alexa\n",
    "software, which runs on its Echo and Dot devices, have clear leads in\n",
    "consumer adoption.\"\"\"\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(text)\n",
    "displacy.render(doc, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдите способ устранить хотябы часть некорректных меток географических объектов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Практическая часть (75%)</h1> \n",
    "* Ссылка на контест: http://www.kaggle.com/c/mipt-ml-fall2018-hw3\n",
    "\n",
    "# Описание форматов\n",
    "\n",
    "Вам выдается 4 файла:\n",
    "\n",
    "* `relevance_train.csv` --- обучающая выборка пар запрос-документ и асессорские метки релевантности (все документы имеют одинаковую релевантность, т.е. можно считать, что выданы просто релевантные документы).\n",
    "* `relevance_test.csv` --- тестовая выборка пар запрос-документ\n",
    "* `queries.csv` --- запросы из relevance_test и relevance_train (в формате id_запроса, текст запроса)\n",
    "* `documents.csv` --- документы из relevance_test и relevance_train (началу документа соответствует строка \"TEXT $n$\", где $n$ - это id данного документа). ВНИМНИЕ: не для всех документов из `relevance_train.csv` есть описание!\n",
    "\n",
    "Колонки в первых трёх файлах могут быть следующего типа:\n",
    "\n",
    "* `QueryId` --- уникальный номер запроса\n",
    "* `DocumentId` --- номер документа, не повторяется для одного запроса\n",
    "* `Relevance` --- асессорская метка релевантности\n",
    "\n",
    "Формат файла ответов приведен ниже. Пары запрос-документ должны соответсвовать файлу `relevance_test.csv` и должны быть упорядочены по убыванию построенной функции релевантности. То есть так, как в поисковой выдаче.\n",
    "QueryId,DocumentId\n",
    "101,5\n",
    "101,0\n",
    "101,9\n",
    "101,13\n",
    "101,17\n",
    "...\n",
    "\n",
    "Файл stopwords содержит стоп-слова, а sample_submission - это пример сабмита, который нужно отправлять в качестве ответа."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Оценка\n",
    "* Чтобы получить удв(3) нужно добить baseline_1.\n",
    "* Более детальная разбалловка будет сформирована после окончания контеста."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ВАЖНО:**\n",
    "Если вы не успели сделать ни одного сабмита до дедлайна, но хотите получить баллы за контест, тогда требуется отправлять вместе с решение скриншот ваших сабмитов (можно смотреть в истории submissions) с указанием того сабмита, который требуется засчитать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_text_num(line):\n",
    "    return int(line.split(' ')[1])\n",
    "\n",
    "def read_text(path):\n",
    "    result = {}\n",
    "    current = 0\n",
    "    with open(path, 'r') as file:\n",
    "        for line in file:\n",
    "            if(line[0] == '*'):\n",
    "                current += 1\n",
    "                result[current] = ''\n",
    "            else:\n",
    "                result[current] += line.replace('\\n', ' ')\n",
    "    return result\n",
    "\n",
    "def read_stop_words(path):\n",
    "    result = []\n",
    "    with open(path, 'r') as file:\n",
    "        for line in file:\n",
    "            result.append(line.replace('\\n', ''))\n",
    "    return result\n",
    "\n",
    "def prepare_data(documents, stopwords):\n",
    "    for key in documents.keys():\n",
    "        doc = re.split(',| ', documents[key])\n",
    "        stemmer = nltk.stem.SnowballStemmer(\"english\")\n",
    "        doc = [stemmer.stem(word).upper() for word in doc if word not in stopwords and len(word) > 0]\n",
    "        documents[key] = doc\n",
    "    return documents\n",
    "    \n",
    "def read_queries(path):\n",
    "    result = {}\n",
    "    with open(path, 'r') as file:\n",
    "        for line in file:\n",
    "            split = line.split(',')\n",
    "            i = int(split[0])\n",
    "            result[i] = ','.join(split[1:])\n",
    "            result[i] = result[i].replace('\\n', '')\n",
    "    return result\n",
    "\n",
    "def get_words(data):\n",
    "    result = []\n",
    "    for item in data.values():\n",
    "        result += item\n",
    "    return result\n",
    "\n",
    "def build_idf(docuemnts, queries):\n",
    "    target_words = get_words(queries)\n",
    "    idf = {}\n",
    "    for word in target_words:\n",
    "        count = 0\n",
    "        for document in documents.values():\n",
    "            if word in document:\n",
    "                count += 1\n",
    "        if count > 0: # если слова нет в документах, то оно не очень важно в tf-idf\n",
    "            idf[word] = -1 * np.log(float(count) / len(documents))\n",
    "    return idf\n",
    "\n",
    "def get_tf(word, document):\n",
    "    count = 0.0\n",
    "    for item in document:\n",
    "        if word == item:\n",
    "            count += 1.0\n",
    "    return count / len(document)\n",
    "\n",
    "def tf_idf(query, document, idf):\n",
    "    tf_idf = 0.0\n",
    "    for word in query:\n",
    "        if word in idf:\n",
    "            tf_idf += get_tf(word, document) * idf[word]\n",
    "    return tf_idf\n",
    "        \n",
    "def rate(query, documents, idf):\n",
    "    keys = documents.keys()\n",
    "    result = []\n",
    "    for key in keys:\n",
    "        result.append((key, tf_idf(query, documents[key], idf)))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = read_text('data/documents.csv')\n",
    "stopwords = read_stop_words('data/stopwords.csv')\n",
    "document_data = prepare_data(documents, stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = read_queries('data/queries.csv')\n",
    "queries_data = prepare_data(queries, stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = build_idf(document_data, queries_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/relevance_test.csv')\n",
    "test = np.array(test).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8771aaf8990141549bab8281b099d683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=42), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rating = []\n",
    "with tqdm(total = len(test)) as pbar:\n",
    "    for item in test:\n",
    "        rating.append((item, rate(queries_data[item], document_data, idf)))\n",
    "        pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top(rating, count):\n",
    "    rating.sort(key = lambda x: -x[1])\n",
    "    return [item[0] for item in rating[:count]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('result.csv', 'w') as file:\n",
    "    file.write('QueryId,DocumentId\\n')\n",
    "    for q_id, res in rating:\n",
    "        top = get_top(res, 5)\n",
    "        for item in top:\n",
    "            file.write(str(q_id)+','+str(item)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QueryId</th>\n",
       "      <th>DocumentId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5</td>\n",
       "      <td>419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>6</td>\n",
       "      <td>323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>6</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6</td>\n",
       "      <td>268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>6</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6</td>\n",
       "      <td>419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7</td>\n",
       "      <td>421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7</td>\n",
       "      <td>406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7</td>\n",
       "      <td>384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>7</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>7</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>72</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>72</td>\n",
       "      <td>354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>72</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>72</td>\n",
       "      <td>338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>72</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>76</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>76</td>\n",
       "      <td>338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>76</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>76</td>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>76</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>78</td>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>78</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>78</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>78</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>78</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>80</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>80</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>80</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>80</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>80</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>81</td>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>81</td>\n",
       "      <td>378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>81</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>81</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>81</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>82</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>82</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>82</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>82</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>82</td>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     QueryId  DocumentId\n",
       "0          2         419\n",
       "1          2         171\n",
       "2          2         383\n",
       "3          2         334\n",
       "4          2         304\n",
       "5          3         154\n",
       "6          3         419\n",
       "7          3          12\n",
       "8          3         106\n",
       "9          3         211\n",
       "10         4         419\n",
       "11         4         171\n",
       "12         4         211\n",
       "13         4         350\n",
       "14         4         154\n",
       "15         5         154\n",
       "16         5         419\n",
       "17         5         211\n",
       "18         5          30\n",
       "19         5          29\n",
       "20         6         323\n",
       "21         6         308\n",
       "22         6         268\n",
       "23         6         257\n",
       "24         6         419\n",
       "25         7         421\n",
       "26         7         406\n",
       "27         7         384\n",
       "28         7          49\n",
       "29         7          87\n",
       "..       ...         ...\n",
       "180       72         305\n",
       "181       72         354\n",
       "182       72         331\n",
       "183       72         338\n",
       "184       72         400\n",
       "185       76         230\n",
       "186       76         338\n",
       "187       76         107\n",
       "188       76         227\n",
       "189       76         218\n",
       "190       78         258\n",
       "191       78         109\n",
       "192       78         241\n",
       "193       78         314\n",
       "194       78         107\n",
       "195       80         305\n",
       "196       80          68\n",
       "197       80          63\n",
       "198       80         107\n",
       "199       80         230\n",
       "200       81         289\n",
       "201       81         378\n",
       "202       81         307\n",
       "203       81         161\n",
       "204       81         111\n",
       "205       82         161\n",
       "206       82           8\n",
       "207       82         216\n",
       "208       82         296\n",
       "209       82         289\n",
       "\n",
       "[210 rows x 2 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = nltk.stem.SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DISTRIBUT'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('distribution').upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aba', 'ca', 'ba']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 'aba,ca ba'\n",
    "re.split(' |,', a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "ml_mipt",
   "language": "python",
   "name": "ml_mipt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
